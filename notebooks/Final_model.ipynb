{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a02285e6",
      "metadata": {
        "id": "a02285e6"
      },
      "source": [
        "AG News Classification with LoRA Fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdcc5329",
      "metadata": {
        "id": "bdcc5329"
      },
      "source": [
        "Install and import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "348ceed6-b684-46c3-8a32-9bb640c9a9d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "348ceed6-b684-46c3-8a32-9bb640c9a9d7",
        "outputId": "2cc8b531-d1f7-4e78-c364-ae0a70842285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: transformers in /home/ms15532/.local/lib/python3.12/site-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /home/ms15532/.local/lib/python3.12/site-packages (3.5.0)\n",
            "Requirement already satisfied: evaluate in /home/ms15532/.local/lib/python3.12/site-packages (0.4.3)\n",
            "Requirement already satisfied: peft in /home/ms15532/.local/lib/python3.12/site-packages (0.15.2)\n",
            "Requirement already satisfied: accelerate in /home/ms15532/.local/lib/python3.12/site-packages (1.6.0)\n",
            "Requirement already satisfied: trl in /home/ms15532/.local/lib/python3.12/site-packages (0.16.1)\n",
            "Requirement already satisfied: bitsandbytes in /home/ms15532/.local/lib/python3.12/site-packages (0.45.5)\n",
            "Requirement already satisfied: filelock in /ext3/miniconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/ms15532/.local/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /ext3/miniconda3/lib/python3.12/site-packages (from transformers) (2.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /ext3/miniconda3/lib/python3.12/site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /ext3/miniconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/ms15532/.local/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /ext3/miniconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ms15532/.local/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/ms15532/.local/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /ext3/miniconda3/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /home/ms15532/.local/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ms15532/.local/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /ext3/miniconda3/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: xxhash in /home/ms15532/.local/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /home/ms15532/.local/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /ext3/miniconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /home/ms15532/.local/lib/python3.12/site-packages (from datasets) (3.11.16)\n",
            "Requirement already satisfied: psutil in /ext3/miniconda3/lib/python3.12/site-packages (from peft) (5.9.0)\n",
            "Requirement already satisfied: torch>=1.13.0 in /ext3/miniconda3/lib/python3.12/site-packages (from peft) (2.6.0+cu118)\n",
            "Requirement already satisfied: rich in /ext3/miniconda3/lib/python3.12/site-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ms15532/.local/lib/python3.12/site-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/ms15532/.local/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /ext3/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/ms15532/.local/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ms15532/.local/lib/python3.12/site-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/ms15532/.local/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ms15532/.local/lib/python3.12/site-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /ext3/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /ext3/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /ext3/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /ext3/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /ext3/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /ext3/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /ext3/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /ext3/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /ext3/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /ext3/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /ext3/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /ext3/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /ext3/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /ext3/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /ext3/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /ext3/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /ext3/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /ext3/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.8.86)\n",
            "Requirement already satisfied: triton==3.2.0 in /ext3/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /ext3/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (75.8.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /ext3/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /ext3/miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /ext3/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /ext3/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /ext3/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /ext3/miniconda3/lib/python3.12/site-packages (from rich->trl) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /ext3/miniconda3/lib/python3.12/site-packages (from rich->trl) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /ext3/miniconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /ext3/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /ext3/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: nvidia-ml-py3 in /home/ms15532/.local/lib/python3.12/site-packages (7.352.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets evaluate peft accelerate trl bitsandbytes\n",
        "!pip install nvidia-ml-py3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cca64f38-d8d2-4313-8295-fbbd43c2a263",
      "metadata": {
        "id": "cca64f38-d8d2-4313-8295-fbbd43c2a263"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import RobertaModel, RobertaTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding, RobertaForSequenceClassification\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "from datasets import load_dataset, Dataset, ClassLabel\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59d6e377",
      "metadata": {
        "id": "59d6e377"
      },
      "source": [
        "## Load Tokenizer and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21f42747-f551-40a5-a95f-7affb1eba4a3",
      "metadata": {
        "id": "21f42747-f551-40a5-a95f-7affb1eba4a3"
      },
      "outputs": [],
      "source": [
        "base_model = 'roberta-base'\n",
        "\n",
        "dataset = load_dataset('ag_news', split='train')\n",
        "tokenizer = RobertaTokenizer.from_pretrained(base_model)\n",
        "\n",
        "# ⬇️ replace your preprocess() with this:\n",
        "def preprocess(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",   # pad to fixed length\n",
        "        max_length=256          # was ≤128 → more context\n",
        "    )\n",
        "\n",
        "tokenized_dataset = (\n",
        "    load_dataset(\"ag_news\", split=\"train\")\n",
        "    .map(preprocess, batched=True, remove_columns=[\"text\"])\n",
        "    .rename_column(\"label\", \"labels\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e07f641-bec0-43a6-8c26-510d7642916a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e07f641-bec0-43a6-8c26-510d7642916a",
        "outputId": "5a954aa4-cf04-495f-fd10-5c9b432f16f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of labels: 4\n",
            "the labels: ['World', 'Sports', 'Business', 'Sci/Tech']\n"
          ]
        }
      ],
      "source": [
        "# Extract the number of classess and their names\n",
        "num_labels = dataset.features['label'].num_classes\n",
        "class_names = dataset.features[\"label\"].names\n",
        "print(f\"number of labels: {num_labels}\")\n",
        "print(f\"the labels: {class_names}\")\n",
        "\n",
        "# Create an id2label mapping\n",
        "# We will need this for our classifier.\n",
        "id2label = {i: label for i, label in enumerate(class_names)}\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9e24afd",
      "metadata": {
        "id": "c9e24afd"
      },
      "source": [
        "## Load Pre-trained Model\n",
        "Set up config for pretrained model and download it from hugging face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZiMiV070GLhP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiMiV070GLhP",
        "outputId": "4bdeb8d0-d57d-4a90-835a-175ba7ad28f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.15.2\n"
          ]
        }
      ],
      "source": [
        "import peft\n",
        "print(peft.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "262a8416-a59c-4ea1-95d9-0b1f81d6094c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "262a8416-a59c-4ea1-95d9-0b1f81d6094c",
        "outputId": "bfd1ebcc-62da-40f9-f37a-48968f0d5ded"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 925,444 || all params: 125,574,152 || trainable%: 0.7370\n"
          ]
        }
      ],
      "source": [
        "# model = RobertaForSequenceClassification.from_pretrained(\n",
        "#     base_model,\n",
        "#     id2label=id2label)\n",
        "# model\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from peft.utils import prepare_model_for_kbit_training\n",
        "\n",
        "# freeze & quantise base RoBERTa in 4‑bit (optional but memory‑friendly)\n",
        "from transformers import BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# bnb_cfg = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True, bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_use_double_quant=True, bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "# )\n",
        "\n",
        "base = AutoModelForSequenceClassification.from_pretrained(\n",
        "    base_model, num_labels=4,\n",
        "    # quantization_config=bnb_cfg, device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# Prepare the model for 4-bit training\n",
        "base = prepare_model_for_kbit_training(base, use_gradient_checkpointing=False)\n",
        "\n",
        "for p in base.parameters():             # freeze backbone\n",
        "    p.requires_grad = False\n",
        "\n",
        "lora_cfg = LoraConfig(\n",
        "    r=6, lora_alpha=12,\n",
        "    target_modules=[\"query\", \"key\", \"value\"],\n",
        "    lora_dropout=0.1,\n",
        "    # mixout_prob=0.05,                   # new quick‑win\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_CLS\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(base, lora_cfg)\n",
        "model.print_trainable_parameters()      # ≈ 414 k  ✅\n",
        "peft_model=model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7413430-be57-482b-856e-36bd4ba799df",
      "metadata": {
        "id": "e7413430-be57-482b-856e-36bd4ba799df"
      },
      "outputs": [],
      "source": [
        "# Split the original training set\n",
        "split_datasets = tokenized_dataset.train_test_split(test_size=640, seed=42)\n",
        "train_dataset = split_datasets['train']\n",
        "eval_dataset = split_datasets['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "652452e3",
      "metadata": {
        "id": "652452e3"
      },
      "source": [
        "## Setup LoRA Config\n",
        "Setup PEFT config and get peft model for finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a769f54e-05ad-4e3c-aae8-d00d1d9dfb2f",
      "metadata": {
        "id": "a769f54e-05ad-4e3c-aae8-d00d1d9dfb2f"
      },
      "outputs": [],
      "source": [
        "# print(\"Trainable parameters:\")\n",
        "# for name, param in peft_model.named_parameters():\n",
        "#     if param.requires_grad:\n",
        "#         print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da45f85c-b016-4c49-8808-6eafa7cb5d1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da45f85c-b016-4c49-8808-6eafa7cb5d1b",
        "outputId": "407dadde-466f-47ac-c711-d91cc524e63a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PEFT Model\n",
            "trainable params: 925,444 || all params: 125,574,152 || trainable%: 0.7370\n"
          ]
        }
      ],
      "source": [
        "print('PEFT Model')\n",
        "peft_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12284b58",
      "metadata": {
        "id": "12284b58"
      },
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ee64c43-fe38-479a-b3c5-7d939a3db4c1",
      "metadata": {
        "id": "0ee64c43-fe38-479a-b3c5-7d939a3db4c1"
      },
      "outputs": [],
      "source": [
        "# To track evaluation accuracy during training\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': accuracy\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "768b4917-65de-4e55-ae7f-698e287535d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "768b4917-65de-4e55-ae7f-698e287535d4",
        "outputId": "21419b45-1d2f-4f55-e56a-fddd2eeba30f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_5544/699797501.py:57: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import torch.nn as nn\n",
        "\n",
        "output_dir=\"results_lora_boosted\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    logging_steps=50,\n",
        "    save_strategy=\"no\",\n",
        "    learning_rate=2e-4,\n",
        "    num_train_epochs=5,\n",
        "    lr_scheduler_type=\"cosine_with_restarts\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    gradient_accumulation_steps=2,\n",
        "    weight_decay=0.01,\n",
        "    bf16=True,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    report_to=None,\n",
        "    label_smoothing_factor=0.2,\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.2)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b848278",
      "metadata": {
        "id": "9b848278"
      },
      "source": [
        "### Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98d9d57d-b57f-4acc-80fb-fc5443e75515",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "98d9d57d-b57f-4acc-80fb-fc5443e75515",
        "outputId": "5b5e7124-bb2f-4005-d563-f18930372189"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mms15532\u001b[0m (\u001b[33mms15532-new-york-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/scratch/ms15532/wandb/run-20250421_201532-guyidnv1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ms15532-new-york-university/huggingface/runs/guyidnv1' target=\"_blank\">results_lora_boosted</a></strong> to <a href='https://wandb.ai/ms15532-new-york-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ms15532-new-york-university/huggingface' target=\"_blank\">https://wandb.ai/ms15532-new-york-university/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ms15532-new-york-university/huggingface/runs/guyidnv1' target=\"_blank\">https://wandb.ai/ms15532-new-york-university/huggingface/runs/guyidnv1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18650' max='18650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18650/18650 2:36:55, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.734500</td>\n",
              "      <td>0.740015</td>\n",
              "      <td>0.898438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.735600</td>\n",
              "      <td>0.731206</td>\n",
              "      <td>0.903125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.710600</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.917188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.711700</td>\n",
              "      <td>0.709947</td>\n",
              "      <td>0.923438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.698100</td>\n",
              "      <td>0.709200</td>\n",
              "      <td>0.915625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.693100</td>\n",
              "      <td>0.702949</td>\n",
              "      <td>0.923438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.696900</td>\n",
              "      <td>0.703487</td>\n",
              "      <td>0.925000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.699200</td>\n",
              "      <td>0.695992</td>\n",
              "      <td>0.937500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.694700</td>\n",
              "      <td>0.695827</td>\n",
              "      <td>0.935937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.677900</td>\n",
              "      <td>0.695755</td>\n",
              "      <td>0.939063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.683200</td>\n",
              "      <td>0.691991</td>\n",
              "      <td>0.940625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.681000</td>\n",
              "      <td>0.692169</td>\n",
              "      <td>0.932813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.687800</td>\n",
              "      <td>0.691051</td>\n",
              "      <td>0.940625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.684000</td>\n",
              "      <td>0.688089</td>\n",
              "      <td>0.931250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.674500</td>\n",
              "      <td>0.688641</td>\n",
              "      <td>0.937500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.687800</td>\n",
              "      <td>0.690172</td>\n",
              "      <td>0.939063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.661500</td>\n",
              "      <td>0.685879</td>\n",
              "      <td>0.935937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.687700</td>\n",
              "      <td>0.687078</td>\n",
              "      <td>0.937500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.667300</td>\n",
              "      <td>0.685511</td>\n",
              "      <td>0.935937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.657100</td>\n",
              "      <td>0.685959</td>\n",
              "      <td>0.940625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.670700</td>\n",
              "      <td>0.680582</td>\n",
              "      <td>0.942187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.669400</td>\n",
              "      <td>0.680435</td>\n",
              "      <td>0.945312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.664000</td>\n",
              "      <td>0.685392</td>\n",
              "      <td>0.943750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.670800</td>\n",
              "      <td>0.681932</td>\n",
              "      <td>0.942187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.676400</td>\n",
              "      <td>0.684159</td>\n",
              "      <td>0.939063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.670600</td>\n",
              "      <td>0.681232</td>\n",
              "      <td>0.943750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.679743</td>\n",
              "      <td>0.945312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.665400</td>\n",
              "      <td>0.678280</td>\n",
              "      <td>0.942187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.672600</td>\n",
              "      <td>0.678539</td>\n",
              "      <td>0.942187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.658700</td>\n",
              "      <td>0.677163</td>\n",
              "      <td>0.940625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.663000</td>\n",
              "      <td>0.678375</td>\n",
              "      <td>0.943750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.669900</td>\n",
              "      <td>0.677900</td>\n",
              "      <td>0.940625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>0.654500</td>\n",
              "      <td>0.678311</td>\n",
              "      <td>0.942187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.666300</td>\n",
              "      <td>0.677775</td>\n",
              "      <td>0.943750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>0.664000</td>\n",
              "      <td>0.677527</td>\n",
              "      <td>0.943750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>0.662900</td>\n",
              "      <td>0.677545</td>\n",
              "      <td>0.942187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18500</td>\n",
              "      <td>0.656200</td>\n",
              "      <td>0.677546</td>\n",
              "      <td>0.943750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5183be7e-514f-4e64-a6f4-314a827e6be5",
      "metadata": {
        "id": "5183be7e-514f-4e64-a6f4-314a827e6be5"
      },
      "source": [
        "## Evaluate Finetuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f88ad420-3f46-4eff-9d71-0ce388163062",
      "metadata": {
        "id": "f88ad420-3f46-4eff-9d71-0ce388163062"
      },
      "outputs": [],
      "source": [
        "def classify(model, tokenizer, text):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
        "    output = model(**inputs)\n",
        "\n",
        "    prediction = output.logits.argmax(dim=-1).item()\n",
        "\n",
        "    print(f'\\n Class: {prediction}, Label: {id2label[prediction]}, Text: {text}')\n",
        "    return id2label[prediction]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc52bb94-5e13-4943-9225-a6d7fd053579",
      "metadata": {
        "id": "fc52bb94-5e13-4943-9225-a6d7fd053579",
        "outputId": "a720ef24-3d9c-4b24-fa8b-b25f88a5f343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Class: 1, Label: Sports, Text: Kederis proclaims innocence Olympic champion Kostas Kederis today left hospital ahead of his date with IOC inquisitors claiming his ...\n",
            "\n",
            " Class: 2, Label: Business, Text: Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindlinand of ultra-cynics, are seeing green again.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Business'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classify( peft_model, tokenizer, \"Kederis proclaims innocence Olympic champion Kostas Kederis today left hospital ahead of his date with IOC inquisitors claiming his ...\")\n",
        "classify( peft_model, tokenizer, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68a3e276-bf8c-4403-8a48-5ef19f2beccf",
      "metadata": {
        "id": "68a3e276-bf8c-4403-8a48-5ef19f2beccf"
      },
      "source": [
        "### Run Inference on eval_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebbc20a2-a1c0-4cb7-b842-f52e4de61ed5",
      "metadata": {
        "id": "ebbc20a2-a1c0-4cb7-b842-f52e4de61ed5"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import evaluate\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_model(inference_model, dataset, labelled=True, batch_size=8, data_collator=None):\n",
        "    \"\"\"\n",
        "    Evaluate a PEFT model on a dataset.\n",
        "\n",
        "    Args:\n",
        "        inference_model: The model to evaluate.\n",
        "        dataset: The dataset (Hugging Face Dataset) to run inference on.\n",
        "        labelled (bool): If True, the dataset includes labels and metrics will be computed.\n",
        "                         If False, only predictions will be returned.\n",
        "        batch_size (int): Batch size for inference.\n",
        "        data_collator: Function to collate batches. If None, the default collate_fn is used.\n",
        "\n",
        "    Returns:\n",
        "        If labelled is True, returns a tuple (metrics, predictions)\n",
        "        If labelled is False, returns the predictions.\n",
        "    \"\"\"\n",
        "    # Create the DataLoader\n",
        "    eval_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=data_collator)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    inference_model.to(device)\n",
        "    inference_model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    if labelled:\n",
        "        metric = evaluate.load('accuracy')\n",
        "\n",
        "    # Loop over the DataLoader\n",
        "    for batch in tqdm(eval_dataloader):\n",
        "        # Move each tensor in the batch to the device\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = inference_model(**batch)\n",
        "        predictions = outputs.logits.argmax(dim=-1)\n",
        "        all_predictions.append(predictions.cpu())\n",
        "\n",
        "        if labelled:\n",
        "            # Expecting that labels are provided under the \"labels\" key.\n",
        "            references = batch[\"labels\"]\n",
        "            metric.add_batch(\n",
        "                predictions=predictions.cpu().numpy(),\n",
        "                references=references.cpu().numpy()\n",
        "            )\n",
        "\n",
        "    # Concatenate predictions from all batches\n",
        "    all_predictions = torch.cat(all_predictions, dim=0)\n",
        "\n",
        "    if labelled:\n",
        "        eval_metric = metric.compute()\n",
        "        print(\"Evaluation Metric:\", eval_metric)\n",
        "        return eval_metric, all_predictions\n",
        "    else:\n",
        "        return all_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "809635a6-a2c7-4d09-8d60-ababd1815003",
      "metadata": {
        "id": "809635a6-a2c7-4d09-8d60-ababd1815003",
        "outputId": "431f441b-aeb5-4118-b0aa-57229e2607b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:05<00:00, 15.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.9421875}\n"
          ]
        }
      ],
      "source": [
        "# Check evaluation accuracy\n",
        "_, _ = evaluate_model(peft_model, eval_dataset, True, 8, data_collator)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75f39087-f2bb-49d3-9fe1-0d812fb30203",
      "metadata": {
        "id": "75f39087-f2bb-49d3-9fe1-0d812fb30203"
      },
      "source": [
        "### Run Inference on unlabelled dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2af62541-2c33-4f16-bb1c-cc969c715cd7",
      "metadata": {
        "id": "2af62541-2c33-4f16-bb1c-cc969c715cd7",
        "colab": {
          "referenced_widgets": [
            "023d9d649e39480093bf2b78cb1a8159"
          ]
        },
        "outputId": "faee0442-c18a-46fc-d7fa-1f227fa840cc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "023d9d649e39480093bf2b78cb1a8159",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 8000\n",
              "})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Load your unlabelled data\n",
        "unlabelled_dataset = pd.read_pickle(\"test_unlabelled.pkl\")\n",
        "test_dataset = unlabelled_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
        "unlabelled_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e60991d3-38b1-4657-8854-408ce66f6b84",
      "metadata": {
        "id": "e60991d3-38b1-4657-8854-408ce66f6b84",
        "outputId": "650261bd-b7a1-4f76-d5fd-a80bba4ae354"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [01:01<00:00, 16.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference complete. Predictions saved to inference_output.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Run inference and save predictions\n",
        "preds = evaluate_model(peft_model, test_dataset, False, 8, data_collator)\n",
        "df_output = pd.DataFrame({\n",
        "    'ID': range(len(preds)),\n",
        "    'Label': preds.numpy()  # or preds.tolist()\n",
        "})\n",
        "df_output.to_csv(os.path.join(output_dir,\"inference_qlora.csv\"), index=False)\n",
        "print(\"Inference complete. Predictions saved to inference_output.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b085ba0-e085-44b9-bb7a-a3f32a3b1d8b",
      "metadata": {
        "id": "9b085ba0-e085-44b9-bb7a-a3f32a3b1d8b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "my_env",
      "language": "python",
      "name": "my_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}